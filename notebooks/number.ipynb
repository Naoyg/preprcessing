{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数値型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "sys.path.append(\"../src\")\n",
    "from data_loader import load_hotel_reserve, load_production, load_production_missing_num\n",
    "\n",
    "customer_tb, hotel_tb, reserve_tb = load_hotel_reserve()\n",
    "production_tb = load_production()\n",
    "production_miss_num = load_production_missing_num()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数値型への変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "float"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(40000 / 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13333\n",
      "13333.333333333334\n"
     ]
    }
   ],
   "source": [
    "# 整数型へ変換\n",
    "print(int(40000 / 3))\n",
    "\n",
    "# 浮動小数点型へ変換\n",
    "print(float(40000 / 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "value    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'value': [40000 / 3]})\n",
    "# データ型の確認\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    13333.333333\n",
       "Name: value, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 整数型へ変換\n",
    "df['value'].astype('int8')\n",
    "df['value'].astype('int16')\n",
    "df['value'].astype('int32')\n",
    "df['value'].astype('int64')\n",
    "\n",
    "# 浮動小数点型へ変換\n",
    "df['value'].astype('float16')\n",
    "df['value'].astype('float32')\n",
    "df['value'].astype('float64')\n",
    "df['value'].astype('float128')\n",
    "\n",
    "# 下記のようにpythonのデータ型を指定できる\n",
    "df['value'].astype(int)\n",
    "df['value'].astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 対数化による非線形な変換\n",
    "予約テーブルのtotal_priceを1000で割ってから、底10で対数化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reserve_tb['total_price_log'] = \\\n",
    "    reserve_tb['total_price'].apply(lambda x: np.log(x / 1000 + 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## カテゴリ化による非線形な変換\n",
    "数値型をカテゴリ化することで非線形な関係を表現することができる。  \n",
    "顧客テーブルを年齢を10きざみのカテゴリ型として追加する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_tb['age_rank'] = \\\n",
    "    (np.floor(customer_tb['age'] / 10) * 10).astype('category')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>home_latitude</th>\n",
       "      <th>home_longitude</th>\n",
       "      <th>age_rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>c_996</td>\n",
       "      <td>44</td>\n",
       "      <td>man</td>\n",
       "      <td>34.465648</td>\n",
       "      <td>135.373787</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>c_997</td>\n",
       "      <td>35</td>\n",
       "      <td>man</td>\n",
       "      <td>35.345372</td>\n",
       "      <td>139.413754</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>c_998</td>\n",
       "      <td>32</td>\n",
       "      <td>woman</td>\n",
       "      <td>43.062267</td>\n",
       "      <td>141.272126</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>c_999</td>\n",
       "      <td>48</td>\n",
       "      <td>woman</td>\n",
       "      <td>38.172800</td>\n",
       "      <td>140.464198</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>c_1000</td>\n",
       "      <td>39</td>\n",
       "      <td>man</td>\n",
       "      <td>35.452412</td>\n",
       "      <td>139.411310</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    customer_id  age    sex  home_latitude  home_longitude age_rank\n",
       "995       c_996   44    man      34.465648      135.373787     40.0\n",
       "996       c_997   35    man      35.345372      139.413754     30.0\n",
       "997       c_998   32  woman      43.062267      141.272126     30.0\n",
       "998       c_999   48  woman      38.172800      140.464198     40.0\n",
       "999      c_1000   39    man      35.452412      139.411310     30.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_tb.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 正規化\n",
    "1. 平均0、分散1に変換する正規化\n",
    "2. 最小値0、最大値1に変換する正規化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 正規化を行うオブジェクトを生成\n",
    "ss = StandardScaler()\n",
    "\n",
    "# fit_transform関数は、fit関数（正規化するための前準備の計算）と\n",
    "# transform関数（準備された情報から正規化の変換処理を行う）の両方を行う\n",
    "result = ss.fit_transform(reserve_tb[['people_num', 'total_price']])\n",
    "\n",
    "reserve_tb['people_num_normalized'] = [x[0] for x in result]\n",
    "reserve_tb['total_price_normalized'] = [x[1] for x in result]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reserve_id</th>\n",
       "      <th>hotel_id</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>reserve_datetime</th>\n",
       "      <th>checkin_date</th>\n",
       "      <th>checkin_time</th>\n",
       "      <th>checkout_date</th>\n",
       "      <th>people_num</th>\n",
       "      <th>total_price</th>\n",
       "      <th>total_price_log</th>\n",
       "      <th>people_num_normalized</th>\n",
       "      <th>total_price_normalized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r1</td>\n",
       "      <td>h_75</td>\n",
       "      <td>c_1</td>\n",
       "      <td>2016-03-06 13:09:42</td>\n",
       "      <td>2016-03-26</td>\n",
       "      <td>10:00:00</td>\n",
       "      <td>2016-03-29</td>\n",
       "      <td>4</td>\n",
       "      <td>97200</td>\n",
       "      <td>4.587006</td>\n",
       "      <td>1.300709</td>\n",
       "      <td>-0.053194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r2</td>\n",
       "      <td>h_219</td>\n",
       "      <td>c_1</td>\n",
       "      <td>2016-07-16 23:39:55</td>\n",
       "      <td>2016-07-20</td>\n",
       "      <td>11:30:00</td>\n",
       "      <td>2016-07-21</td>\n",
       "      <td>2</td>\n",
       "      <td>20600</td>\n",
       "      <td>3.072693</td>\n",
       "      <td>-0.483753</td>\n",
       "      <td>-0.747822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r3</td>\n",
       "      <td>h_179</td>\n",
       "      <td>c_1</td>\n",
       "      <td>2016-09-24 10:03:17</td>\n",
       "      <td>2016-10-19</td>\n",
       "      <td>09:00:00</td>\n",
       "      <td>2016-10-22</td>\n",
       "      <td>2</td>\n",
       "      <td>33600</td>\n",
       "      <td>3.543854</td>\n",
       "      <td>-0.483753</td>\n",
       "      <td>-0.629935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r4</td>\n",
       "      <td>h_214</td>\n",
       "      <td>c_1</td>\n",
       "      <td>2017-03-08 03:20:10</td>\n",
       "      <td>2017-03-29</td>\n",
       "      <td>11:00:00</td>\n",
       "      <td>2017-03-30</td>\n",
       "      <td>4</td>\n",
       "      <td>194400</td>\n",
       "      <td>5.275049</td>\n",
       "      <td>1.300709</td>\n",
       "      <td>0.828240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r5</td>\n",
       "      <td>h_16</td>\n",
       "      <td>c_1</td>\n",
       "      <td>2017-09-05 19:50:37</td>\n",
       "      <td>2017-09-22</td>\n",
       "      <td>10:30:00</td>\n",
       "      <td>2017-09-23</td>\n",
       "      <td>3</td>\n",
       "      <td>68100</td>\n",
       "      <td>4.235555</td>\n",
       "      <td>0.408478</td>\n",
       "      <td>-0.317080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  reserve_id hotel_id customer_id     reserve_datetime checkin_date  \\\n",
       "0         r1     h_75         c_1  2016-03-06 13:09:42   2016-03-26   \n",
       "1         r2    h_219         c_1  2016-07-16 23:39:55   2016-07-20   \n",
       "2         r3    h_179         c_1  2016-09-24 10:03:17   2016-10-19   \n",
       "3         r4    h_214         c_1  2017-03-08 03:20:10   2017-03-29   \n",
       "4         r5     h_16         c_1  2017-09-05 19:50:37   2017-09-22   \n",
       "\n",
       "  checkin_time checkout_date  people_num  total_price  total_price_log  \\\n",
       "0     10:00:00    2016-03-29           4        97200         4.587006   \n",
       "1     11:30:00    2016-07-21           2        20600         3.072693   \n",
       "2     09:00:00    2016-10-22           2        33600         3.543854   \n",
       "3     11:00:00    2017-03-30           4       194400         5.275049   \n",
       "4     10:30:00    2017-09-23           3        68100         4.235555   \n",
       "\n",
       "   people_num_normalized  total_price_normalized  \n",
       "0               1.300709               -0.053194  \n",
       "1              -0.483753               -0.747822  \n",
       "2              -0.483753               -0.629935  \n",
       "3               1.300709                0.828240  \n",
       "4               0.408478               -0.317080  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reserve_tb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 外れ値の除去\n",
    "極端に大きな値や小さな値は予測モデルを構築するときに悪影響を与えることが多く、前処理で除去することが求められる。  \n",
    "正規分布を前提にした、最も簡単でよく扱われる外れ値検出の方法は、平均値から標準偏差の一定値倍以上離れた値を除外すること。一般に一定倍数は3より大きな値を設定する。  \n",
    "予約テーブルの予約合計金額(total_price)において、平均値から標準偏差の3倍以内の値に収まる予約レコードのみに絞る。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reserve_tb = reserve_tb[\n",
    "    (abs(reserve_tb['total_price'] - np.mean(reserve_tb['total_price'])) /\n",
    "     np.std(reserve_tb['total_price']) <= 3)\n",
    "].reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 主成分分析による次元圧縮\n",
    "要素間の相関を排除し、できるだけ少ない情報の損失で、新たな要素を定義する。モデルの精度が大きく上がることはないが、データの可視化を容易にすることができたり、新たな次元から新たな発見を見つけることができる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "累積寄与率: 1.0\n",
      "各次元の寄与率: [0.97897794 0.02102206]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# n_componentsに、主成分分析で変換後の次元数を設定\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "# 主成分分析を実行\n",
    "# pcaに主成分分析の変換パラメータが保存され、返り値に主成分分析後の値が返される\n",
    "pca_values = pca.fit_transform(production_tb[['length', 'thickness']])\n",
    "\n",
    "# 累積寄与率と寄与率の確認\n",
    "print('累積寄与率: {0}'.format(sum(pca.explained_variance_ratio_)))\n",
    "print('各次元の寄与率: {0}'.format(pca.explained_variance_ratio_))\n",
    "\n",
    "# predict関数を利用し、同じ次元圧縮処理を実行\n",
    "pca_newvalues = pca.transform(production_tb[['length', 'thickness']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数値の補完\n",
    "欠損値の前処理を行う前に、どのような欠損なのかを確認する必要がある。\n",
    "- MCAR (Missing Completely At Random)：偶然に起きている完全なランダムな欠損。例えば、室温を測る温度センサーから送られてくるデータが一定の確率で破損する場合。\n",
    "- MAR (Missing At Random)：欠損した項目データとは関係なく、他の項目データに依存した欠損。例えば、室温を測る温度センサーから送られてくるデータが、湿度が高いほど破損する確率が高くなる場合。\n",
    "- MNAR (Missing Not At Random)：欠損した項目データに依存した欠損。例えば、室温を測る温度センサーから送られてくるデータが40度を超えると破損する場合。\n",
    "\n",
    "データを補完する方法にはさまざまな方法がある。\n",
    "1. 定数による補完\n",
    "2. 集計値による補完\n",
    "3. 欠損していないデータに基づく予測値によって補完\n",
    "4. 時系列の関係から補完\n",
    "- 欠損しているデータの前後のデータから欠損値を予測して補完する方法\n",
    "- 例えば、10:01の温度データが欠けているときに、10:00の温度データと10:02の温度データの平均値を利用して補完する\n",
    "- 時間に対して連続している値が対称であれば、MCAR、MARにおいて有効\n",
    "5. 多重代入法\n",
    "- 特定の値を欠損部分に代入することでMCAR以外の場合にはバイアスが生じてしまう\n",
    "- 補完したデータセットを複数作成し、そのそれぞれのデータセットに対して解析を行う\n",
    "- 複数の結果を統合することでバイアスの少ない結果を得る\n",
    "- MCAR、MARにおいて有効\n",
    "6. 最尤法\n",
    "- 多重代入法と同様に、本来のデータのばらつきよりも補完後のデータのばらつきが小さくする手法\n",
    "- 潜在変数を導入し、EMアルゴリズムを用いて尤度を最大化することで欠損値を推定する\n",
    "- MCAR、MARにおいて有効\n",
    "\n",
    "MCAR、MARにおいては、多重代入法または最尤法を利用することが一般的"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### thicknessが欠損しているレコードを削除する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace関数によって、Noneをnanに変換\n",
    "# （Noneを指定する際には文字列として指定する必要がある）\n",
    "production_miss_num.replace('None', np.nan, inplace=True)\n",
    "\n",
    "# dropna関数によって、thicknessにnanを含むレコードを削除\n",
    "production_miss_num.dropna(subset=['thickness'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定数補完\n",
    "欠損しているthicknessを1の値で補完する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_miss_num = load_production_missing_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace関数によって、Noneをnanに変換\n",
    "production_miss_num.replace('None', np.nan, inplace=True)\n",
    "\n",
    "# fillna関数によって、thicknessの欠損値を1で補完\n",
    "production_miss_num['thickness'].fillna(1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 平均値補完"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_miss_num = load_production_missing_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace関数によって、Noneをnanに変換\n",
    "production_miss_num.replace('None', np.nan, inplace=True)\n",
    "\n",
    "# thicknessを数値型に変換（Noneが混ざっているため数値型になっていない）\n",
    "production_miss_num['thickness'] = \\\n",
    "    production_miss_num['thickness'].astype('float64')\n",
    "\n",
    "# thicknessの平均値を計算\n",
    "thickness_mean = production_miss_num['thickness'].mean()\n",
    "\n",
    "# thicknessの欠損値をthicknessの平均値で補完\n",
    "production_miss_num['thickness'].fillna(thickness_mean, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PMMによる多重代入法\n",
    "**PMM** (Predictive Mean Matching)\n",
    "1. 欠損データを除いたデータから欠損データを予測する回帰モデルを構築\n",
    "2. 構築した回帰モデルの係数と誤差分散の分布を計算\n",
    "3. 係数と誤差分散の分布から新たな係数と誤差分散の値を生成\n",
    "4. 3で生成した係数と誤差分散の値にしたがった回帰モデルから予測値を計算\n",
    "5. 欠損していない観測データの中から予測値に最も近いデータを補完値として採用\n",
    "6. データを補完して、新たな構築した回帰モデルの係数と誤差分散の分布を計算、3に戻る\n",
    "\n",
    "3-6を補完する値の分布が安定するまで繰り返し、安定してから指定したデータセットの数分の補完値が得られたら終了となる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_miss_num = load_production_missing_num()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'MICE' from 'fancyimpute' (/home/aoyg/miniconda3/envs/myenv/lib/python3.8/site-packages/fancyimpute/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mセル31 を /home/aoyg/preprcessing/notebooks/number.ipynb\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/aoyg/preprcessing/notebooks/number.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfancyimpute\u001b[39;00m \u001b[39mimport\u001b[39;00m MICE\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/aoyg/preprcessing/notebooks/number.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m# replace関数によって、Noneをnanに変換\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu/home/aoyg/preprcessing/notebooks/number.ipynb#X54sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m production_miss_num\u001b[39m.\u001b[39mreplace(\u001b[39m'\u001b[39m\u001b[39mNone\u001b[39m\u001b[39m'\u001b[39m, np\u001b[39m.\u001b[39mnan, inplace\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'MICE' from 'fancyimpute' (/home/aoyg/miniconda3/envs/myenv/lib/python3.8/site-packages/fancyimpute/__init__.py)"
     ]
    }
   ],
   "source": [
    "from fancyimpute import MICE\n",
    "\n",
    "# replace関数によって、Noneをnanに変換\n",
    "production_miss_num.replace('None', np.nan, inplace=True)\n",
    "\n",
    "# mice関数を利用するためにデータ型を変換（mice関数内でモデル構築をするため）\n",
    "production_miss_num['thickness'] = \\\n",
    "    production_miss_num['thickness'].astype('float64')\n",
    "production_miss_num['type'] = \\\n",
    "    production_miss_num['type'].astype('category')\n",
    "production_miss_num['fault_flg'] = \\\n",
    "    production_miss_num['fault_flg'].astype('category')\n",
    "\n",
    "# ダミー変数化（「第9章 カテゴリ型」で詳しく解説)\n",
    "production_dummy_flg = pd.get_dummies(\n",
    "    production_miss_num[['type', 'fault_flg']], drop_first=True)\n",
    "\n",
    "# mice関数にPMMを指定して、多重代入法を実施\n",
    "# n_imputationsは取得するデータセットの数\n",
    "# n_burn_inは値を取得する前に試行する回数\n",
    "mice = MICE(n_imputations=10, n_burn_in=50, impute_type='pmm')\n",
    "\n",
    "# 処理内部でTensorFlowを利用\n",
    "production_mice = mice.multiple_imputations(\n",
    "    # 数値の列とダミー変数を連結\n",
    "    pd.concat([production_miss_num[['length', 'thickness']],\n",
    "               production_dummy_flg], axis=1)\n",
    ")\n",
    "\n",
    "# 下記に補完する値が格納されている\n",
    "production_mice[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エラーにより実行できない"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('myenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d90a39672d555971ab95a5a373ccc6b42d2b1580cc6dac5514e2241c079d03cb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
